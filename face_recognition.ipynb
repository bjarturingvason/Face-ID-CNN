{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import NMF\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, DepthwiseConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS    \n",
    "def preprocess(file_path):\n",
    "    \n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    # Preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (128,128))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    # img = img.numpy()\n",
    "    img = img / 255.0\n",
    "\n",
    "    # H, W, C = img.shape                      # (100, 100, 3) 255.0     # non-negative\n",
    "    # X = img.reshape(H, W * C)    \n",
    "    #             # → (100, 300)   2-D, non-negative\n",
    "    # nmf = NMF(n_components=60, init=\"nndsvda\", max_iter=200)\n",
    "    # Ww = nmf.fit_transform(X)                 # (100, 50)\n",
    "    # Hmat = nmf.components_                   # (50, 300)\n",
    " \n",
    "    # # low-rank reconstruction back to image\n",
    "    # img_lowrank = Ww @ Hmat\n",
    "    # img_lowrank = img_lowrank.reshape(H, W, C) \n",
    "    # img_back = tf.convert_to_tensor(img_lowrank, dtype=tf.float32)   # ► NumPy → Tensor\n",
    "\n",
    "    # Return image\n",
    "    return img\n",
    "\n",
    "def flip(image):\n",
    "    image\n",
    "\n",
    "    flipped=[]\n",
    "    for r in range(len(image[:])):\n",
    "        row=[]\n",
    "        for i in range(len(image[r])):\n",
    "            row.append(image[-r][-i])\n",
    "        flipped.append(row)\n",
    "    return flipped\n",
    "\n",
    "def reduce(image,amount):\n",
    "\n",
    "    reduced=[]\n",
    "\n",
    "    #we pick out only a select number of the pixels from the image.\n",
    "\n",
    "\n",
    "    row_list=np.linspace(0,len(image[:]),int((len(image[:]))/ amount ))\n",
    "    row_indexes=[]\n",
    "    for i in range(len(row_list)):\n",
    "        row_indexes.append(int(row_list[i]))\n",
    "\n",
    "\n",
    "    column_list=np.linspace(0,len(image[0]),int((len(image[0]))/ amount ))\n",
    "    column_indexes=[]\n",
    "    for i in range(len(column_list)):\n",
    "        column_indexes.append(int(column_list[i]))\n",
    "\n",
    "\n",
    "    for r in range(len(image[:])):\n",
    "    \n",
    "        if r in row_indexes:\n",
    "        \n",
    "            row=[]\n",
    "            for i in range(len(image[r])):\n",
    "                if i in column_indexes:\n",
    "                    row.append(image[r][i])\n",
    "\n",
    "    \n",
    "            reduced.append(row)\n",
    "    return reduced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET=os.listdir('DATASET/train')\n",
    "\n",
    "SET=[]\n",
    "for j in range(len(DATASET)):\n",
    "    person=DATASET[j]\n",
    "    folder=os.listdir('DATASET/train/' + person)\n",
    "\n",
    "    image_list= []\n",
    "    for i in range(len(folder)):\n",
    "        image_list.append(preprocess('DATASET/train/' + person + '/' + folder[i]))\n",
    "    SET.append(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET LOFT FOR GPU\n",
    "#We want to avoid out-of-memory errors by creating a sealing to GPU usage\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') #defining/naming my gpu in python\n",
    " \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True) #setting a loft on it so it doesn't go crazy with memory, leading to oom errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for directory in os.list.dir('DATASET/train'):\n",
    "    for file in os.listdir('DATASET/train', directory):\n",
    "        EX_PATH=os.path.join('DATASET/train',directory, file)\n",
    "        NEW_PATH=os.path.join(NEG_PATH,file)\n",
    "        os.replace(EX_PATH,NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(class_to_imgs, n_pos_per_class=100, n_neg_total=10000, seed=None):\n",
    "    \"\"\"\n",
    "    Build two lists:\n",
    "        pairs  – list of (path1, path2)\n",
    "        labels – 1 for positive (same person), 0 for negative\n",
    "    Args\n",
    "        class_to_imgs : dict  {class_name: [path, path, ...]}\n",
    "        n_pos_per_class : how many positive pairs to draw *for each* class\n",
    "        n_neg_total     : how many negative pairs to draw overall\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    classes = list(class_to_imgs.keys())\n",
    "\n",
    "    posval, posanch = [], []\n",
    "    negval, neganch = [], []\n",
    "\n",
    "    # positives\n",
    "    for cls, imgs in class_to_imgs.items():\n",
    "        if len(imgs) < 2:\n",
    "            continue\n",
    "        for _ in range(n_pos_per_class):\n",
    "            a, b = rng.sample(imgs, 2)\n",
    "            posval.append(a)\n",
    "            posanch.append(b)\n",
    "            \n",
    "\n",
    "    # negatives\n",
    "    for _ in range(n_neg_total):\n",
    "        c1, c2 = rng.sample(classes, 2)           # two different people\n",
    "        negval.append(rng.choice(class_to_imgs[c1]))\n",
    "        neganch.append(rng.choice(class_to_imgs[c2]))\n",
    "        \n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(posval), tf.data.Dataset.from_tensor_slices(negval), tf.data.Dataset.from_tensor_slices(posanch), tf.data.Dataset.from_tensor_slices(neganch)\n",
    "\n",
    "def collect_images(root_dir):\n",
    "    \"\"\"\n",
    "    Return {class_name: [img_path, img_path, …]} for every sub‑folder in root_dir.\n",
    "    Accepts JPG/JPEG/PNG files only.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    exts = ('.jpg', '.jpeg', '.png')\n",
    "    \n",
    "    for cls in os.listdir(root_dir):\n",
    "        cls_path = os.path.join(root_dir, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        \n",
    "        imgs = [\n",
    "            os.path.join(cls_path, f)\n",
    "            for f in os.listdir(cls_path)\n",
    "            if f.lower().endswith(exts)\n",
    "        ]\n",
    "        \n",
    "        if imgs:                     # keep folders that have at least one image\n",
    "            data[cls] = imgs\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the paths of the pairs to feed the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_collection = collect_images('/Users/hn/Documents/DTU/V25/Imaging/Project/1/train')\n",
    "posval, negval, posanch, neganch = make_pairs(path_collection, seed=123, n_neg_total=1, n_pos_per_class=1)\n",
    "\n",
    "positives = tf.data.Dataset.zip((posval,neganch, tf.data.Dataset.from_tensor_slices(tf.ones(len(posval)))))\n",
    "negative = tf.data.Dataset.zip((negval, neganch, tf.data.Dataset.from_tensor_slices(tf.ones(len(negval)))))\n",
    "data = positives.concatenate(negative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(): \n",
    "    inp = Input(shape=(128,128,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='PReLU')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='PReLU')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='PReLU')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='PReLU')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    #c_out = DepthwiseConv2D(kernel_size=(H, W), use_bias=False)(feature_map) We can test this here\n",
    "\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')\n",
    "\n",
    "embedding = make_embedding()\n",
    "\n",
    "\n",
    "class L1Dist(Layer):\n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Siamese layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         87520384    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 87,524,481\n",
      "Trainable params: 87,524,481\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(128,128,3))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(128,128,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n",
    "\n",
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001\n",
    "\n",
    "#checkpoint set\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)\n",
    "\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/3\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "0.6452886 1.0 1.0\n",
      "\n",
      " Epoch 2/3\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "0.5317935 1.0 1.0\n",
      "\n",
      " Epoch 3/3\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "0.27402255 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train(train_data, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
